{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import ast\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'output/test-2/'\n",
    "cluster_data = pd.read_csv(path+'1_step_user_groups.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_tags = pd.read_csv(path+'1_step_tags_clusters.txt', sep='\\t')\n",
    "cluster_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCompleteUserlist(userlist, cluster_dim):\n",
    "    userlist = list(ast.literal_eval(userlist))\n",
    "    result = []\n",
    "    if cluster_dim > 1:\n",
    "        for userdata in userlist:\n",
    "            result.append(userdata[0])\n",
    "    else:\n",
    "        result.append(userlist[0])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data['all_users'] = cluster_data.apply(lambda x: getCompleteUserlist(x['list_users'], x['num_users']), axis=1)\n",
    "cluster_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read tags features\n",
    "features = pd.read_csv('tagsdata.csv')\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = list(features.columns[1:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid(data):\n",
    "    arrays = [np.array(x[header]) for index, x in data.iterrows()]\n",
    "    \n",
    "    return np.sum(arrays, axis=0)/data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_tags(centroid, alltags, K):\n",
    "    alltags['distance'] = alltags.apply(lambda x: np.linalg.norm(np.array(x[header]) - centroid), axis=1)\n",
    "    \n",
    "    return alltags.sort_values(by='distance')[:K]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_to_add = features[features['cluster'].isin([-1, 0])]\n",
    "tags_to_add.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for c in cluster_data['id_cluster']:\n",
    "    cluster_centroid = centroid(features[features['cluster'] == c])\n",
    "\n",
    "    tags_2 = closest_tags(cluster_centroid, tags_to_add, 10)\n",
    "    tags_to_add.drop(tags_2.index, inplace=True, axis=0)\n",
    "    \n",
    "    result.append(tuple((c, list(tags_2['id_node']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_cluster_tags = pd.DataFrame(result, columns=['id_cluster', 'hashtags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output/test-2/v2/2_step_tags_clusters.txt', 'w') as outfile:\n",
    "    outfile.write('n_cluster\\thashtags\\n')\n",
    "    for c in extended_cluster_tags['id_cluster']:\n",
    "        cluster = extended_cluster_tags[extended_cluster_tags['id_cluster'] == c]['hashtags'].values[0]\n",
    "    \n",
    "        outfile.write('{}\\t{}\\n'.format(c, ','.join(list(cluster))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store for next iterations/runs\n",
    "usedtags = pickle.load(open('output/user-tags-list.pkl', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute participation for the second set of tags extracted\n",
    "tempResult = []\n",
    "for u in usedtags:\n",
    "    u_vector = usedtags[u]\n",
    "    \n",
    "    if len(u_vector)>0:\n",
    "        u_result = [u]\n",
    "        for c in extended_cluster_tags['id_cluster']:\n",
    "            c_vector = set(extended_cluster_tags[extended_cluster_tags['id_cluster'] == c]['hashtags'].values[0])\n",
    "            participation = float(len(u_vector.intersection(c_vector)))/len(u_vector)\n",
    "            u_result.append(participation)\n",
    "    else:\n",
    "        u_result = [u]+[0 for i in extended_cluster_tags['id_cluster']]\n",
    "    tempResult.append(tuple(u_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_header = ['username']+[c for c in extended_cluster_tags['id_cluster']]\n",
    "participationTable = pd.DataFrame(tempResult, columns=result_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participationTable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participationTable.to_csv('output/test-2/v2/2_step_user_participation.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_step_users = set()\n",
    "for userlist in cluster_data['all_users']:\n",
    "    for u in userlist:\n",
    "        first_step_users.add(u[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output/test-2/v2/2_step_user_groups.csv', 'w') as outfile:\n",
    "    outfile.write('id_cluster\\tnum_users\\tlist_users\\n')\n",
    "    for i in extended_cluster_tags['id_cluster']:\n",
    "        group = participationTable[participationTable[i] != 0.0]\n",
    "        group.sort_values(by=i, ascending = False, inplace=True)\n",
    "        \n",
    "        userlist = [tuple((x['username'], x[i])) for index, x in group.iterrows() if x['username'] not in first_step_users]\n",
    "        \n",
    "        dim = len(userlist)\n",
    "        outfile.write('{}\\t{}\\t{}\\n'.format(i, dim, str(userlist).strip('[]')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of clusters and extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_step = cluster_tags.merge(cluster_data, left_on='n_cluster', right_on='id_cluster')[['id_cluster','dim','num_users']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_cluster_tags['dim_2'] = extended_cluster_tags.apply(lambda x: len(x['hashtags']), axis=1)\n",
    "extended_cluster_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_2 = []\n",
    "for i in range(1,37):\n",
    "    group = participationTable[participationTable[i] != 0.0]\n",
    "    group.sort_values(by=i, ascending = False, inplace=True)\n",
    "    \n",
    "    # filter previous users to verify how many users we are extending the clusters to\n",
    "    # but in principle the participation is updates for all users and it increases for the ones of the first step!\n",
    "    userlist = [tuple((x['username'], x[i])) for index, x in group.iterrows() if x['username'] not in first_step_users]\n",
    "\n",
    "    dim = len(userlist)\n",
    "    user_2.append(tuple((i, dim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_step = first_step.merge(extended_cluster_tags[['id_cluster','dim_2']], on='id_cluster')\\\n",
    "                        .merge(pd.DataFrame(user_2, columns=['id_cluster', 'num_users_2']), on='id_cluster')\n",
    "#second_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_step.set_index('id_cluster', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_step.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_step.columns = ['#tag', '#users', '#tag_2', '#users_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_step.plot(kind='bar', figsize=(16,10), width=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Participation of the core users may increase after adding the extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute participation for the overall hashtags cluster (core + extended)\n",
    "# NB: it is possible that users have not a complete participation, since a lot of hashtags still are not included\n",
    "tempResult = []\n",
    "for u in usedtags:\n",
    "    u_vector = usedtags[u]\n",
    "    \n",
    "    if len(u_vector)>0:\n",
    "        u_result = [u]\n",
    "        for c in extended_cluster_tags['id_cluster']:\n",
    "            c_vector = set(extended_cluster_tags[extended_cluster_tags['id_cluster'] == c]['hashtags'].values[0])\\\n",
    "                        .union(set(cluster_tags[cluster_tags['n_cluster'] == c]['hashtags'].values[0]))\n",
    "            participation = float(len(u_vector.intersection(c_vector)))/len(u_vector)\n",
    "            u_result.append(participation)\n",
    "    else:\n",
    "        u_result = [u]+[0 for i in extended_cluster_tags['id_cluster']]\n",
    "    tempResult.append(tuple(u_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_header = ['username']+[c for c in extended_cluster_tags['id_cluster']]\n",
    "participationTable = pd.DataFrame(tempResult, columns=result_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participationTable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participationTable.to_csv('output/test-2/v2/complete_user_participation.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Community Network Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'output/test-2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part1 = pd.read_csv(path+'1_step_user_participation.csv')\n",
    "part2 = pd.read_csv(path+'v2/2_step_user_participation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgetable = []\n",
    "\n",
    "for i in range(1,37):\n",
    "    group = part1[part1[str(i)] > 0.0]\n",
    "    \n",
    "    \n",
    "    userlist = [tuple(('core_{}'.format(i), x['username'], x[str(i)])) for index, x in group.iterrows()]\n",
    "    edgetable = edgetable + userlist\n",
    "\n",
    "for i in range(1,37):\n",
    "    group = part2[part2[str(i)] > 0.0]\n",
    "    \n",
    "    \n",
    "    userlist = [tuple(('extension_{}'.format(i), x['username'], x[str(i)])) for index, x in group.iterrows()]\n",
    "    edgetable = edgetable + userlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusteredges = [tuple(('core_{}'.format(i), 'extension_{}'.format(i), 1)) for i in range(1,37)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = pd.DataFrame(clusteredges + edgetable, columns=['source','target','weight'])\n",
    "edges.to_csv('output/test-2/edgetable_2.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.DataFrame(columns=['id', 'type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeSize(cluster):\n",
    "    cid = int(cluster['id'].split('_')[1])\n",
    "    \n",
    "    if 'core' in cluster['id']:\n",
    "        return len(cluster_tags[cluster_tags['n_cluster'] == cid]['hashtags'].values[0].split(','))\n",
    "    \n",
    "    elif 'extension' in cluster['id']:\n",
    "        return len(list(extended_cluster_tags[extended_cluster_tags['id_cluster'] == cid]['hashtags'].values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeLabel(cluster):\n",
    "    cid = int(cluster['id'].split('_')[1])\n",
    "    \n",
    "    if 'core' in cluster['id']:\n",
    "        return cluster_tags[cluster_tags['n_cluster'] == cid]['hashtags'].values[0]\n",
    "    elif 'extension' in cluster['id']:\n",
    "        return ','.join(list(extended_cluster_tags[extended_cluster_tags['id_cluster'] == cid]['hashtags'].values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = pd.DataFrame(edges['source'].unique(), columns=['id'])\n",
    "n1['type'] = 'cluster'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1['size'] = n1.apply(lambda x: computeSize(x), axis=1)\n",
    "n1['label'] = n1.apply(lambda x: computeLabel(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2 = edges[['target']]\n",
    "n2['type'] = 'user'\n",
    "n2.columns = ['id', 'type']\n",
    "n2['size'] = 1\n",
    "n2['label'] = n2.apply(lambda x: x['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.concat([n1, n2])\n",
    "nodes.drop_duplicates().to_csv('output/test-2/nodetable_2.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of neighbors hashtags to consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " usedtags = pickle.load(open('output/user-tags-list.pkl', 'r'))\n",
    "def k_selection(max_K, tags_to_add):\n",
    "    k_vec = range(10, max_K)\n",
    "    added_users = []\n",
    "    \n",
    "    for k in k_vec:\n",
    "        print k\n",
    "        result = []\n",
    "        for c in cluster_data['id_cluster']:\n",
    "            cluster_centroid = centroid(features[features['cluster'] == c])\n",
    "\n",
    "            tags_2 = closest_tags(cluster_centroid, tags_to_add, k)\n",
    "            tags_to_add.drop(tags_2.index, inplace=True, axis=0)\n",
    "\n",
    "            result.append(tuple((c, list(tags_2['id_node']))))\n",
    "            \n",
    "        extended_cluster_tags = pd.DataFrame(result, columns=['id_cluster', 'hashtags'])\n",
    "\n",
    "        curr_added_users = []\n",
    "        for c in extended_cluster_tags['id_cluster']:\n",
    "            c_vector = set(extended_cluster_tags[extended_cluster_tags['id_cluster'] == c]['hashtags'].values[0])\n",
    "            num_users = 0\n",
    "            for u in usedtags:\n",
    "                u_vector = usedtags[u]\n",
    "\n",
    "                if len(u_vector)>0:\n",
    "                    u_result = [u]\n",
    "                    participation = float(len(u_vector.intersection(c_vector)))/len(u_vector)\n",
    "                    \n",
    "                    if participation > 0.0:\n",
    "                        num_users += 1\n",
    "                        \n",
    "            curr_added_users.append(num_users)\n",
    "        \n",
    "        added_users.append(np.mean(curr_added_users))\n",
    "        \n",
    "    return added_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average number of users per cluster added in the second run\n",
    "k_selection(15, features[features['cluster'].isin([-1, 0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
